\section{Phrasing Additive Manufacturing as a Machine Learning Problem}\label{phrasing}
\input{SectionII/DesignSpace}
\input{SectionII/DataTypes}
\input{SectionII/Assumptions}
\input{SectionII/Unsupervised}
\input{SectionII/Supervised}

\begin{table*}
\caption{Several of the most widely used machine learning algorithms that have been used in materials science are compared.} \label{ML}
\begin{tabular}{p{2.25cm}|p{2.25cm}|p{3cm}|p{4cm}|p{4cm}}
\raggedright Class of Algorithm & Examples & Applications & Strengths & Constraints \\ \hline \hline
Weighted neighborhood clustering & Decision trees, k-Nearest neighbor & \raggedright Regression, Classification, Clustering and similarity & These algorithms are robust against uncertainty in data sets and can provide intuitive relationships between inputs and outputs. See Ref. \cite{Quinlan1986} for a primer on clustering. & They can be susceptible to classification bias toward descriptors with more data entries than others. \\ \hline

\raggedright Nonlinear dimensionality reduction & \raggedright t-SNE, Kernel ridge regression, Multidimensional metric scaling &\raggedright  Dimensionality reduction, Clustering and similarity, Input/output visualization, Descriptor analysis, Regression, Predictive modeling &\raggedright These algorithms are robust against nonlinear input/output relationships and can provide intuitive projections of the material input/output space. For accessible examples, see Refs. \cite{Tenenbaum2000, Roweis2000}. & Projections can represent unphysical, difficult to interpret relationships. Global relationships can also be lost when nonlinear dimensionality reduction results are projected onto lower-dimensional spaces.\\ \hline

\raggedright Linear dimensionality reduction & \raggedright Principle component analysis (PCA), Support vector regression (SVR) & Dimensionality reduction, Clustering and similarity, Input/output visualization, Descriptor analysis, Regression, Predictive modeling & \raggedright This type of algorithm can produce orthogonal basis sets which reproduce the training data space. They can also provide quick and accurate regression analysis. For a primer on PCA specifically, see Ref. \cite{Bro2014}. & The relationships studied must be linear in nature, and these algorithms are susceptible to bias when descriptors are scaled differently. \\ \hline

Search algorithms & \raggedright Genetic algorithms, Evolutionary algorithms & Searching a material space to optimize on a certain condition, Lowest-energy state searches, Crystal structure prediction &  \raggedright Search algorithms are intuitive for material properties that can be described geometrically, such as topology optimization for weight reduction. They are efficient at searching spaces with multiple local extrema, such as finding local maxima of quality in multidimensional design spaces. &  These algorithms are highly dependent upon selection and mutation criteria. For a useful application of genetic algorithms to process characterization, see Ref. \cite{Grefenstette1986}. \\

\end{tabular}
\end{table*}

%\subsection{Design space considerations}
%\label{subsec:DMC_design_space}
%When attempting to optimize an AM workflow for a particular property, it is important to consider the size and complexity of the design space.
%The size of this parameter space indicates the value of data-driven exploration.
%While it may be most valuable to seed the design exploration by performing orthogonal experiments first, typical experimental conditions facilitate fine exploration of a small subset of the design space.
%For example, a build plate of 44 samples is likely to be all of the same composition with each sample only differing by their part orientation on the build plate.
%This hindrance suggests that seeding your design space from the currently available or past experiments will lead to desired output more quickly.
%
%\subsection{Data pipeline}
%\label{subsec:DMC_data}
%There are a wide variety of computational tools associated with applying ML to materials science problems.
%As there are not many large, robust, data sources for AM, developing a data pipeline should be a top priority for ML-focused AM teams.
%Table\ref{table:data_tools} describes some common tools and how they may be useful to AM workflows.
%It may be useful to breakdown the active learning process into four steps: identification, collection, condensation, and analysis.
%
%\subsubsection{Collection}
%When optimizing a large design space, data collection may consist of two phases: uninformed collection and informed collection.
%Initially, when no experiments have been performed, it is most useful to pick a subset of experiments that are most dissimilar to perform first.
%In figure\ref{fig:SL}, due to the low dimensionality of the space, the most dissimilar experiments are easy to see.
%For high-dimensionality design spaces, unsupervised learning techniques (t-SNE, PCA) may be useful to determine the most dissimilar experiments.
%
%During both phases of data collection, it is useful to consider the number of format of initial data sources.
%For AM, it is likely data will come from an instrument in the lab (i.e. XCT, mechanical testing) or previously recorded literature data.
%When collecting data from literature tools like WebPlotDigitizer and Tabula are valuable for collecting data accurately and quickly.
%Once data sources have been identified and some experiments have been performed it may be useful to unify disparate data into unique records.
%For smaller projects, this could be as simple as transferring all relevant data to a csv.
%For larger projects, users may want to consider an open data format, like JSON or SQL, to maintain robust data records.
%
%\subsubsection{Condensation}
%Condensing sparse data into an "ML-ready" dataset may vary greatly between projects but there are a few considerations specific to AM.
%If multiple team members are collaborating on a project, it may be useful to consider standardizing input and output names ("Contour laser speed" vs. "Speed of contour laser").
%This is important for both the research as it will ensure recorded properties are not incorrectly interpreted and for machine learning as unique strings are likely interpreted as different descriptors.
%When working with large design spaces, Python packages like Numpy and Pandas do well to provide quick feedback for the density of a dataset and can highlight sparse areas of the design space.
%
%During this phase, a researcher may also consider calculating features from raw data.
%For example, the XCT may only record the size and position of pores but some pore statistics (min/max pore size) may prove useful for modeling.
%During this step, the reseacher should apply their domain expertise to properly engineer useful features.
%
%\subsubsection{Analysis}
%Once some amount of a design space has been explored and the collected data has been condensed to the relevant properties of interest, machine learning algorithms may be able to guide which experiment to preform next.
%Python packages like sklearn, tensorflow, keras, and OpenCV contain a variety of algorithms with well documented use cases.
%For materials specific examples of implementing a sequential learning workflow, see the learn-citrination github respository.
%Once an informative model has been generated, experiments should be optimized in batches that allow the model to improve over many cycles.
%At this point, informed data collection, condensation, and analysis should be repeated until the design goal is realized.



%\begin{table*}
%    \renewcommand{\arraystretch}{0.8}
%    \setlength{\tabcolsep}{5pt}
%    \begin{center}
%        \begin{tabular}{@{}llll@{}}
%            \toprule
%            Data source (instrument/software) & file type & processing tools & "ML-ready" output \\ \midrule
%            \hline
%            \hline
%            X-Ray tomography (Zeiss Xradia Versa) & .tiff & image featurizer & vectorized image \\
%            X-Ray tomography (TRACR) & .txt, .csv & Python (pypif, pandas, citriantion-client) & porosity statistics \\
%            X-Ray diffraction (Panalytical empyrean) & .xy & Python (pypif, csv, pandas) & XRD features (\% desired phase) \\
%            Optical microscopy (Keyence VHX-5000) & .tiff & image featurizer & vectorized image (grain size and distributions) \\
%            Uniaxial tensile testing (MTS 370) & .xy & Python (Hough transform algorithm) & real-valued mechanical properties \\
%            Composition (TOF-SIMS) & & Python (pymatgen, matminer, magpie) & composition feature vectors \\
%            Semi-structured web page & .html & Python (requests, beautifulsoup) & csv-formatted records \\
%            Semi-structured pdf (txt-based) & .pdf & tabula, AbbyyFineReader, Python (pdftotext) & csv-formatted records \\
%            ML packages & & Python (sklearn, tensorflow, keras, OpenCV) & \\
%            \hline
%            \bottomrule
%        \end{tabular}
%        \caption{Common tools and packages for preparing data for ML applications}
%        \label{table:data_tools}
%    \end{center}
%\end{table*}


%\subsection{Preparing data for machine learning}
%
%For materials synthesis applications, signal from machine learning models is often limited by the amount of data and the speed at which data can be collected.
%Many standard algorithms are suitable to correlate high-dimensional inputs and outputs in the AM design space.
%
%To prepare experimentally generated data for input to a machine learning model, python scripting and other automation tools are typically employed.
%For AM synthesis optimization, data is generated at many disparate sources.
%For example, after a build plate is printed, the porosity of each sample is determined through X-ray tomography while other mechanical properties are determined through tensile testing.
%Data collected this way is typically resolved through a master record in which data from many instruments and synthesis steps is stored.
%Also, storing these data in a human and machine-readable format allows for quick error checking and data maniuplation to be performed while still being accessible for machine learning.
%Table XX highlights a variety of computational tools and Python packages and their relevance to AM synthesis optimization.


%\begin{figure}
%  \includegraphics[width=0.9\linewidth]{SectionII/design_example.png}
%  \caption{Illustrating a sequential learning workflow. In this example, there are 16 total possible experiments and
%   4 experiments are performed for initial data collection. To reduce potential bias due subsampling of the input space,
%  the most dissimilar experiments should be performed first. After populating some amount of the design space,
%  machine learning should be used to begin informative data collection until design goal is realized.}
%  \label{fig:SL}
%\end{figure}

%%%

