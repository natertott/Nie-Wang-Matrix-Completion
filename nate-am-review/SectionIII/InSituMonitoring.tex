\subsubsection{In Situ Process Monitoring and Feedback}
Computer vision is a class of image recognition algorithms that have been developed for automated feature identification in images. Intelligent computer vision utilizes machine learning algorithms to identify objects and features in images and time-series data. 

Computer vision can be employed in additive manufacturing to monitor the printing process, such as measuring temperature profiles, observing melt pool morphologies, and automatically detecting defect formation. Doing so will require methods for in situ process monitoring and data collection. Thus far, in situ control in AM has been consistently ranked as one of the most-needed technologies for advancing the technology \cite{Berumen2010, Tapia2014, Mani2017}. The combination of rapid solidification and the small length scales of AM solidification can make traditional process monitoring approaches difficult. Machine learning can fill in gaps where human-specified process monitoring models are insufficient.

Process monitoring involves acquisition of realtime signals which can be processes to reveal information about manufacturing. McKeown et al. used dynamic transmission electron microscopy to measure solidification rates in powder bed AM \cite{McKeown2016}. Bertoli et al. also characterized cooling rates using high speed imaging \cite{Bertoli2017}. Raplee et al. used thermography to monitor the solidification and cooling rates of electron beam powder bed fusion, then related the temperature profiles to defect and microstructural characteristics \cite{Raplee2017}. Distortion of parts due to thermal cycling was investigated by Denlinger et al. by means of thermocouples in contact with the build substrate \cite{Denlinger2015}. All of these methods are amenable to aid by computer vision. 

There are two areas of need for in situ measurement: \begin{itemize}
	\item Processing of signals real time to identify features of the AM process
	\item Multi objective feedback and control
\end{itemize} \textbf{There are several review articles on AM (Tapia, for example) which could go here, or could go in the intro paragraph of Section III.c}

Many of the difficulties in real time signal processing is the complexity and number of signals being acquired. Identifying features of interest in a signal becomes difficult when the necessary signal features to identify are not known. Researchers are well aware that defects form during the additive process. Which signals to monitor and what about the signals are indicative of a defect is not known. 

Setup for the following information:
\begin{itemize}	
	\item Explain the concept of identifying features in images (filters, SIFT/SURF)
	\item Explain template matching using a dictionary of identified features
	\item Explain the concept of `learning' filters through a CNN
	\item Explain the use of CNNs in AM process monitoring
	\item Move Gobert to case study section
\end{itemize}

Convolutional neural networks (CNNs) have proven to be one of the best computer vision approaches for identifying complex features in images \textbf{citation?}. At the highest level, CNNs use large databases of labeled information to learn features in the image that indicate whether or not certain human-identified objects are present. The level of abstractness of the object is arbitrary, so long as the dataset contains enough images with each feature to be identified. This is an improvement over current methods whereby humans develop models specifically to identify features of the printing process. Human-specified models for defect detection -- \textbf{search around the literature you've cited for an example of a human-specified model that is very specific to the problem being address, perhaps Abdelrahman? \cite{Abdelrahman2017}.} -- can be limited in their ability to identify edge cases, as well as in their ability to detect multiple types of defect formation. Convolutional neural networks can identify multiple features or defects in an image simultaneously. A downside to CNNs is that they require \textbf{very} large datasets (thousands of images, at the least) of labeled data to be successful. Neural networks have already been implemented for in situ AM analysis by Scime et al. \cite{Scime2018}, Yuan et al \cite{Yuan2018}. 

Another computer vision approach is called \textit{template matching} and does not require the same dataset size as CNNs. Template matching is the process of comparing computer-vision identified `keys' in an image with a database of keys associated with a certain feature. For example, powder inclusion in a melt pool can often be characterized by a local change in reflectivity in the melt pool near the particle \textbf{cite???? where are you coming up with this, or are you asssuming?}. A feature identification algorithm such as the scale invariant feature transform (SIFT) \cite{Lowe2004} or speeded-up robust features (SURF) \cite{Bay2008} can identify common characteristics of a powder inclusion in an image. Template matching involves using an algorithm like SIFT and SURF to identify features in an image, then compare those features with a database of typical AM features, like porosity or powder inclusion. If keys of the feature in the image closely match a key in the template database then it is likely that feature exists in the image. 

