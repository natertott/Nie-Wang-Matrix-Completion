\subsubsection{Featurization of Qualitative Image Data}
The intuition gained from human interpretation of images is not always encodable in a way that is compatible with models. A human might make a complicated interpretation of an image, such as ``the microstructure is mostly acicular, with some prior grains present, and a string of pores near the boundary." Surely, such a description conjures an image in the reader's head of what such a microstructure might look like. Encoding the same information into a finite element mesh of a microstructure isn't necessarily straightforward. It can be accomplished, for sure, but transforming an observed microstructure into quantitative information requires time-consuming methods. 

Image recognition algorithms are making strides at automating quantification of information from images, while also being able to produce qualitative descriptions of the images. Information such as the size of grains, orientation of grains, presence of cracks or pores, different phases, and more can be automatically identified through computer vision. DeCost et al. have made strides in turning metallographs into sets of quantitative information \cite{DeCost2015, DeCost2017, DeCost2017a}. 

In one particular example, DeCost et al. utilize scale invariance feature transform (SIFT) in order to identify possible features in images. The SIFT algorithm is a widely used algorithm for feature identification and is implemented in many open-source packages, such as OpenCV for C++ or Python \textbf{cite OpenCV}. SIFT relies on identifying regions of maximal and minimal intensity in successively blurred versions of an image. The gradient of pixels are regions of extremal intensity are then computed, resulting in a keypoint descriptor which encodes the size and orientation of a feature, as well as generates a descriptor for identifying that object. The idea behind SIFT is that similar features across images will have similar descriptors. This way, common features can be identified across images. 

DeCost et al. performed SIFT on a database of microstructure images across several alloys \cite{DeCost2015}. The ``features'' that were identified across \textit{all} images were then clustered by $k$-means clustering to identify a dictionary of features. Human investigation can assign qualitative labels to clusters, such as ``$\alpha$ grain" or ``pore" or ``grain boundary." Now, new images can be analyzed with SIFT and their features can be compared to the dictionary of human-interpretable feature descriptors. 

Not only does this process partially automate analysis of images it also automates translation of image-level information into quantitative information. Grain size can be measured by the number of pixels in an identified grain. Orientation of grains in the image can be determined from the values of the keypoint descriptor. The number of pores in an image can be counted as the number of features which match ``pore" in the dictionary. Of course, a human could perform all of this with a ruler and their eyes. However, a computer can perform the same process much faster and on many more images. 

Chowdhury et al. took a more expansive approach to performing feature identification in microstructures. In particular, they were looking to classify microstructures as either dendritic or non dendritic. Chowdhury employed 8 different feature identification methods for a dataset of images. Classification was performed using support vector machines (SVM), Na\"ive Bayes, nearest neighbor, and a committee of the three previous classification methods \cite{Chowdhury2016}. Chowdhury's wide approach to image classification compared the predictive ability of all combinations of feature identification and classification methods, achieving classification accuracies above 90\%. 