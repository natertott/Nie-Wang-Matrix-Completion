\section{Learning from the Past: Moving Towards Database-Driven Design of Additive}
The genesis of this review article was motivated by successes of material scientists in applying data-driven methods over the past three decades. The scientific and engineering process of studying AM has developed similarly to other fields in materials science; particularly, materials design through thin film deposition and high throughput density functional theory have applied machine learning to find new materials with new properties. Materials science investigations in these regimes are focused around combinatorial screening of manufacturing or modeling inputs to search for optimized properties. As such, there is a good deal of information to be learned from these previous investigations which can be applied to ML of AM. 

By the early 1990s, specifically engineered materials had become foundational in the modern technological world as more and more applications relied on advances in solid-state chemistry and physics. High-$T_C$ superconducting electrodes, high--energy density lithium-ion batteries, higher efficiency solid-state silicon transistors, and highly efficient photosensitive detectors and energy converters were all being sought. Improvements in the properties of commonly used materials would be advantageous for the scientific and engineering community.

At the same time, high-throughput material synthesis methods had also become a reality. Various forms of manufacturing and synthesis techniques allowed scientists and engineers to rapidly produce a span of materials at different stoichiometries with different precursors, different crystalline structures, and different properties. Chemical vapor deposition, metallorganic chemical vapor deposition, physical vapor deposition, and atomic layer deposition, among other techniques, became commonplace for the manufacturing of sensors, batteries, photovoltaics, electronics, and the like \cite{Hampden-Smith1995, Gilmer1998, Mercey1999, Mitzi2001}. Furthermore, electron microscopy and lab-scale X-ray diffraction techniques had matured to become routine measurements. Materials scientists now had the ability to quickly manufacture a range of different samples, then characterize their phases, structures, and properties faster than ever. Even further, computational materials science techniques matured during this time. Packages such as the Vienna Ab initio Simulation Package (VASP) were being used across the field for DFT simulations of material and chemical systems. As long as a material system was not too complicated, it could be accurately modeled in VASP. Materials scientists could manufacture and study materials systems at a wider and deeper scope than ever before. The problem, however, was \textit{where} in the design space to manufacture.

Consider just the subset of all binary alloys: the number of different combinations of elements and stable structures has not yet been fully explored, even though scientists understand many of the underlying physical phenomena \cite{Pilania2013}. An AB metal crystal with a unit cell containing 10 atoms has $10^{11}$ different combinations \cite{Oganov2006}. It is possible to provide rigorous, fundamental quantum mechanical descriptions of atomic lattices for binary alloys, but it is not possible, in general, to design that rigorous description to have a specific set of desired properties. For example, scientists can readily predict the properties of a binary alloy and describe its formation; however, there are many possible binary alloys. It is often not a matter of a lack of understanding, but rather picking the right place to look.

In additive manufacturing, the same is true. High-fidelity computational models of AM exist and are widespread in literature \cite{Francois2017}. The number of different manufacturing processes and alloys being developed is also widespread. If a scientist starts with an alloy, a deposition process, and manufacturing conditions, then it is reasonable to create an accurate computational model that will predict the final properties. The process of modeling and experimental verification can be time-intensive and cannot necessarily suggest \textit{better} conditions under which to manufacture, however. Searching combinatorial spaces manually is currently the best manner to find local maxima of quality.

The ab initio process relies on having accessible methods of measuring a given material property. This typically means that the property can be quantified from a first-principles computation or an experimental measurement. The point is, the property itself needs to be stated in terms of measurable, mathematically expressible quantities. In the high-throughput ab initio materials science community, researchers often discuss the use of descriptors, which are chosen to screen materials for their properties. The very first ab initio investigations studied descriptors that were directly calculated from a first-principles approach; that is, they could be calculated from thermodynamic principles or by numerically solving the Schr\"odinger equation for a crystal.

For example, the superconducting electrode community has been searching for high-$T_C$ superconductors since the discovery of the phenomenon. In 1995, Xiang et al. at Lawrence Berkeley National Laboratory proposed the idea of combinatorial materials science for discovering such a superconductor \cite{Xiang1995}. Starting with seven binary compound precursors, they used an RF magnetron sputtering gun to synthesize 128 copper-oxide thin films that might exhibit superconducting properties. Xiang's group then characterized the superconducting properties at various composition points on the thin film substrates. These measurements were related back to manufacturing conditions. Since the thin film had continuously varying composition based on manufacturing conditions, they were able to observe how the property varied over composition and structures. The results of their research were two new superconducting films, with $T_C$ of 80 and 90 K, respectively. This research was an early demonstration of the success of high-throughput methods.

Xiang et al. found that novel material systems can be screened from ab initio calculations of their properties with reasonable certainty. That is, their first-principles calculations matched well with the high-throughput characterization results. With this knowledge, scientists can design tests in a more informed manner without having to manufacture parts that definitely will not exhibit the properties of interest. The material systems in the study that seemed promising---meaning they exhibited desired properties, were stable in a solid state, or (ideally) both---were manufactured and characterized. High-throughput synthesis, computation, and characterization proved to be a feasible process by which to explore the structure-property space of superconductors. Following the study by Xiang et al., research teams across the globe began to investigate different niches of unexplored materials territory. 

Initially, high-throughput ab initio experimentation like that of Xiang et al. was a common method of studying structure-property relationships. Investigations of these types are motivated by a logical thread of reasoning: if it is known that one stable crystal structure exhibits a desired property, then slightly altered crystal structures might exhibit the same---or better---properties. A scientist can manufacture a number of similar structures with slightly altered compositions, characterize their properties, then comment on trends in the composition-structure-property relationships. Fields whose materials are manufactured through chemical or physical deposition are especially suited for this type of research \cite{Koinuma2004}. Common deposition techniques have enough degrees of freedom to allow for continuous composition variation within a single sample, which allows for continuous mapping of composition-structure-property relationships \cite{Long2007, Long2009, Kusne2015a}. 

The same is true in additive manufacturing. It is expected that parts manufactured with identical geometries at identical conditions should demonstrate the same properties analogously to crystal structures and material properties. To reproduce mechanical properties like strength, ductility, hardness, etc. in AM, it must be determined \textit{where} in the design space they occur. Following observation and characterization, the necessary design parameters can be adjusted to adopt those properties for other geometries, compositions, processes, or more. Operators can precisely control heat source parameters and energy density to produce a desired property. This is how the materials science community has conducted engineering research for a long time.

Computational high-throughput DFT studies also demonstrated success in the early 2000s. Computational ab initio has proven to accurately reproduce reality in many regimes when compared to experimental results \cite{Curtarolo2005}. While research groups may have access to rapid deposition techniques, it is expensive to manufacture swaths of composition-structure space. It also takes considerable time to manufacture and characterize samples. Considering the vastness of unexplored material compositions, structures, and properties, high-throughput experimental techniques can become infeasible. 

By the late 1990s and early 2000s, computing power and accessibility skyrocketed while price dropped drastically, affording the materials science community the opportunity to combinatorially fill out the materials design space. The computational materials community began to \textit{start} with the high-throughput method in the materials design process, as opposed to starting purely from first-principles or domain knowledge. The high-throughput ab initio method found many successes in materials science, ranging from the high-$T_C$ superconducting community \cite{Kolmogorov2006} to lithium-ion battery development \cite{Chen2012, Hautier2013, Kang2006, Kirklin2013}, novel alloy discovery \cite{Hautier2010, Ciobanu2005}, thermoelectric materials \cite{Wang2011, Yan2015}, and novel electronic and piezoeletric materials \cite{Setyawan2010, Roy2012, Bennett2012, DeJong2015}. For a review of ab initio solid-state physics, chemistry, and materials research through the early 2000s, see Ref. \cite{Curtarolo2013}.

As more and more materials scientists adopted the high-throughput method, huge repositories of new data were being created, often the results of DFT calculations. Databases of information were generated and disseminated to the scientific public \cite{ Setyawan2010, Setyawan2011, Curtarolo2012, Curtarolo2012a, Jain2011, Jain2013}. Large repositories of information can quickly become overwhelming and the amount of time and resources required to comb through the results is unreasonable. Even an expert in materials science cannot be expected to decipher physical trends from millions of data entries consisting of different descriptors all obtained by different means from different studies. The same will be true for AM and computational models of AM processes.

With all this computation being done, scientists could now compare across materials domains. So many research groups around the world were generating materials data that it became important to analyze trends across studies, materials, and disciplines. As a result, large materials informatics databases began appearing in academia. While databases have been crucial to materials science for some time---think the International Crystal Structure Database or Linus Pauling Files---these new databases were interactive, collaborative, and ever-growing. The more that research teams conducted computational studies, the more that materials informatics grew.

The generation of databases that are accessible to the scientific public is a primary step on the roadmap of the Materials Genome Initiative \cite{DePablo2014}. In an effort to reduce the design time on material systems, programs like the Materials Project incorporate data taken from a wide range of simulation methods into an open-source, accessible database. The Materials Project also features electronic, structural, and thermodynamic calculations of different materials as well as an automated workflow for doing DFT computations of material systems \cite{Jain2013}. Interactive computational databases provide not only a repository for materials scientists to store data but also a way for new research teams to adopt computational materials approaches. 

These databases provide an additional benefit absent from high-throughput studies of individual material systems. Typically, a single ab initio investigation will focus on a specific material system, property, or composition range. By having large databases of information, calculations can be applied that find trends across these different material systems; thus, scientists can discover more fundamental phenomena that relate to the field of materials science as a whole. 

In generating databases, scientists are attempting to achieve several different goals. A primary goal is open access to material information and a framework for material discovery. Having multiple teams across the world work on the same problem through a common interface allows for a deeper understanding of the field as more and more perspectives are generated. Similarly, having many different teams across the world work on different problems means that the space of possible material structures or properties is being fully explored. After all, it is very likely that improved or new materials have compositions or structures never before observed. The materials science community is trying to disseminate information quickly and efficiently to improve the search for new materials. In fact, some pipelines for high-throughput computation and analysis have included consideration of publication timelines in their processes \cite{Foster2015}. The goal is to improve the field as quickly as possible while still generating consistent, accurate, and well-researched content. The same approach is aptly suited for characterizing AM systems and parts. Research and development in additive manufacturing has progressed to a level where large amounts of experimental and computational data are being generated, in the same manner that occurred for materials science in the early 2000s. Adopting machine learning algorithms to the simulation and experimental validation of printing processes will advance scientific understanding of the physics of AM while also expediting the design, development, and qualification of additively manufactured materials. 
 
