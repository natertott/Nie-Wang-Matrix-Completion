\paragraph{Learning from the Past: Moving Towards Database-Driven Design of Additive Technologies}
The scientific approaches to studying additive manufacturing discussed herein -- parametric analysis, computational modeling, in situ monitoring, and the like -- produce data. The application of machine learning to these scientific approaches likewise produces data. All of this data comprises a subset of the AM design space. The integration of this data into multi parameter, multi physics, multi printer datasets increases both the size of the design space that can be explored as well as the depth/accuracy at which certain regions of the design space can be modeled. Making AM process-structure and process-property data open and accessible to the scientific public accelerates the rate at which data-driven approaches can help to advance AM research and engineering. This potential is evident in examining some more mature examples of the use of data-driven approaches in materials science and engineering, which we proceed to briefly review in this section to motivate the development of data-driven approaches for AM. 

Databases of process-structure and process-property relationships are not a new concept in materials science. Databases like the Linus Pauling Files or International Crystal Structure Database have been widely used for materials design. Domain-specific databases are also being generated from high throughput experimental and computational investigations that have occurred over the past thirty years. Experimental high throughput investigations have also been used in materials science for many decades \cite{Xiang1995}. Common deposition techniques (sputter, plasma, vapor, etc.) have enough degrees of freedom to allow for continuous compositional variation within a single sample, which allows for continuous mapping of composition-structure-property relationships \cite{Long2007, Long2009, Kusne2015a}. These combinatorial synthesis methods present analogous design space challenges to AM: the number of possible input combinations obscures many of the important underlying process-structure phenomenon. It has long been established that synthesizing and characterizing large combinatorial catalogues of samples can lead to the discovery of materials with optimized properties faster than a theory-driven approach by itself \cite{Ceder1998, Pilania2013}. High throughput deposition studies with chemical vapor deposition, metallorganic chemical vapor deposition, physical vapor deposition, and atomic layer deposition, among other techniques are commonplace for the manufacturing of sensors, batteries, photovoltaics, electronics, shape memory alloys, and the like \cite{Hampden-Smith1995, Gilmer1998, Mercey1999, Mitzi2001, Cui2006,Dwivedi2008, Jin2013}. Furthermore, the parameters of interest in these studies can sometimes be quickly catalogued using high throughput characterization techniques like laboratory X-ray diffraction and electron probe microanalysis \cite{Gregoire2014, Ren2017}. These combinatorial studies culminate in large libraries of material properties listed as a function of composition. As far back as the 1990s, data-driven algorithms were being applied to search and discover using these large libraries of composition-property data. Evolutionary and genetic algorithms were trained on composition to predict stable crystal structure and material properties \cite{Deaven1995, Morris1996, Woodley1999, Stucke2003, Wolf2000}. Even neural networks, which did not have the widespread use then that they have now, were being applied for the prediction of crystal structures based on composition \cite{Sumpter1996}.

Modeling challenges in materials science have also been tackled using large databases with machine learning. Packages such as the Vienna Ab initio Simulation Package (VASP) have been employed for high throughput searches of stable material systems with a wide range of properties. The stability and maturity of these packages have enabled the reliable automated calculation of new stoichiometries and new phases \cite{Glass2006} and enabled the automated and semi-automated search for new functional materials\cite{Hafner2006}. As these methods have improved, computational high throughput investigations continue to increasingly match and provide complementary information to experimental measurements \cite{Curtarolo2005}.  High throughput density functional theory (DFT) studies generate quite a bit of data and are therefore well equipped for machine learning and database-driven design. The application of high throughput DFT is widespread for design of materials with all sorts of properties including high temperature superconductors \cite{Kolmogorov2006}, lithium ion batteries \cite{Kang2006, Chen2012, Kirklin2013}, molecule design \cite{Mannodi-Kanakkithodi2016, Butler2018}, cathode materials \cite{Hautier2013}, piezoelectrics \cite{Roy2012}, ferroelectrics \cite{Bennett2012}, corrosion resistant films \cite{Ciobanu2005}, and thermoelectrics \cite{Wang2011, Yan2015}. Each of these studies, like parametric studies in additive, vary a set number of model input parameters and measure a material property as the dependent response.

Yet many of the same modeling obstacles exist in DFT as in AM, such as a lack of transferability between models and the computational expense of large material systems. The design space problem exists here as well -- there are so many possible compositional combinations that knowing \textit{where} to look is difficult. Machine learning was proposed as a solution for obstacles in high throughput DFT as early as 2005 \cite{Morgan2005}.  Large unit cells whose properties cannot be directly calculated using DFT are often approximated using machine learning approaches like neural networks \cite{Behler2015}, genetic algorithms \cite{Hart2005}, and principal component analysis \cite{Snyder2012}. Studies applying machine learning to databases of computational information have gone beyond tackling computational problems. In some cases, the studies have revealed previously unobserved or uncharacterized relationships between crystal structure information and materials properties \cite{Ghiringhelli2015}.

In other efforts to reduce the time to design and deploy new materials, programs like the Materials Project incorporate data taken from a wide range of experimental and computational methods into an open-source, accessible database. The Materials Project also features electronic, structural, and thermodynamic calculations of different materials as well as an automated workflow for doing DFT computations of material systems \cite{Jain2011, Jain2013}. Other databases of materials information include AFLOWLib \cite{Curtarolo2012, Curtarolo2012a}, the Harvard Clean Energy Project \cite{Hachmann2011}, Japan's National Institute of Material Science \cite{NIMS}, and the Open Quantum Materials Database \cite{Saal2013}. Some pipelines for high-throughput computation and analysis have included consideration of publication timelines in their processes \cite{Foster2015}. These databases offer a multitude of benefits to materials researchers. First and foremost, publicly accessible databases offer an infrastructure for the free flow of experimental and computational results. Synergy between research groups becomes easier as data is shared more freely. Furthermore, many of these online databases also provide tools for performing material design. The Materials Project offers a design interface, whereby users can specify a set of material properties and are provided with a list of likely candidate materials. Other projects, like AFLOW, allow for fast high-throughput DFT calculations of a wide range of material systems.

The generation of databases that are accessible to the scientific public is a primary step on the roadmap of the Materials Genome Initiative \cite{DePablo2014}. Much of the development of materials databases have focused on computationally-derived materials information. Infrastructure and standards need to be developed that allow for sharing of experimental data that is understandable and usable by many researchers. Data journals are becoming more common for sharing datasets from scientific investigations and are making strides in standardizing data-sharing infrastructure \cite{Wilkinson2016}, along with the publication of datasets themselves for public use \cite{DeJong2015, Kim2017}. By examining the development of image processing databases outside of materials science, it is evident that the collection and distribution of image databases have enabled rapid developments in the field of computer vision. Many of the more common objectives with computer vision -- autonomous navigation, face recognition, object recognition, image segementation -- have databases that are catalogued in online repositories like CVonline \cite{CVonline} and VisionScience \cite{VisionScience}. Learning from these other fields, open sharing of AM microstructure image databases will aid in the development of segmentation and identification algorithms that are suited for materials, and more specifically AM-specific problems.

Having open, accessible databases improves the rate at which machine learning can be applied to design for additive manfuacturing. Machine learning as a tool driving materials design was proposed some time ago. Review articles have explored the many and varied uses of machine learning across materials science, with many of the applications finding great success \cite{Kalidindi2016, Ramprasad2017, Gubernatis2018}. A review article on best practices for machine learning in materials science can be found in the work of Wagner et al\cite{Wagner2016}. Open sharing of databases also tackles a problem in ICME approaches to AM; that is, the \textit{integration} of multiple data sources. AM incorporates relevant physics over many different time and length scales, to the extent that a single research group is unlikely to have access to all pertinent information. Open sharing of data sets, whether it is computationally derived, experimental, or images, allows research groups to incorporate multiple physics simultaneously. Furthermore, it will accelerate the rate at which AM materials research is performed as higher fidelity machine learning models can be built with more and diverse datasets.

Additive manufacturing should move toward the same types of infrastructure for open data sharing. The combinatorial problems in additive are widespread and cover many, many length scales. Large institutions may have the resources to link time- and length-scales in additive manufacturing. Smaller research groups are often limited to studying a single process phenomenon and do not necessarily have means to integrate their knowledge into other additive manufacturing studies. The generation of additive databases allows for a democratization of research and an acceleration of the pace at which additive manufacturing advances are made.
